# local-llm example environment

# Qdrant
LOCAL_LLM_QDRANT_URL=http://localhost:6333
LOCAL_LLM_QDRANT_API_KEY=
LOCAL_LLM_QDRANT_COLLECTION_NAME=fir_dissertations

# Embeddings
LOCAL_LLM_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# LLM
# Choose between:
# - ollama (default, local model via Ollama)
# - openai (or any OpenAI-compatible HTTP API)
LOCAL_LLM_LLM_PROVIDER=ollama

# Ollama settings
LOCAL_LLM_OLLAMA_MODEL=mistral
LOCAL_LLM_OLLAMA_BASE_URL=http://localhost:11434

# OpenAI or OpenAI-compatible HTTP API settings
# When using provider "openai", you must set at least:
# - LOCAL_LLM_OPENAI_API_KEY
# Optionally override:
# - LOCAL_LLM_OPENAI_BASE_URL (default: https://api.openai.com/v1)
# - LOCAL_LLM_OPENAI_MODEL (default: gpt-4o-mini)
LOCAL_LLM_OPENAI_BASE_URL=https://api.openai.com/v1
LOCAL_LLM_OPENAI_API_KEY=
LOCAL_LLM_OPENAI_MODEL=gpt-4o-mini

